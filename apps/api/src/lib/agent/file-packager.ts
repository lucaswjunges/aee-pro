/**
 * Pack/unpack workspace files for the Fly.io agent service.
 *
 * - packProjectFiles: reads all project files from R2 and returns JSON array
 * - syncFilesBack: writes changed files from agent back to R2/D1
 */

import { eq, and } from "drizzle-orm";
import { workspaceFiles } from "@aee-pro/db/schema";
import type { Database } from "../../db/index";

export interface PackedFile {
  path: string;
  content: string; // base64 for binary, UTF-8 for text
  mimeType: string;
  isBinary: boolean;
}

/**
 * Read all project files from R2 and pack them for transport to agent service.
 */
export async function packProjectFiles(
  projectId: string,
  userId: string,
  db: Database,
  r2: R2Bucket
): Promise<PackedFile[]> {
  const files = await db
    .select()
    .from(workspaceFiles)
    .where(eq(workspaceFiles.projectId, projectId));

  const packed: PackedFile[] = [];

  for (const file of files) {
    // Skip output files (PDFs) â€” they'll be regenerated by the agent
    if (file.isOutput) continue;

    const object = await r2.get(file.r2Key);
    if (!object) continue;

    const isBinary = isBinaryMime(file.mimeType);

    let content: string;
    if (isBinary) {
      const buffer = await object.arrayBuffer();
      const bytes = new Uint8Array(buffer);
      // Chunk-based base64 encoding
      let binary = "";
      for (let i = 0; i < bytes.length; i += 8192) {
        binary += String.fromCharCode(
          ...bytes.subarray(i, Math.min(i + 8192, bytes.length))
        );
      }
      content = btoa(binary);
    } else {
      content = await object.text();
    }

    packed.push({
      path: file.path,
      content,
      mimeType: file.mimeType,
      isBinary,
    });
  }

  return packed;
}

/**
 * Sync changed files from agent service back to R2 and D1.
 */
export async function syncFilesBack(
  changedFiles: PackedFile[],
  projectId: string,
  userId: string,
  db: Database,
  r2: R2Bucket
): Promise<{ created: number; updated: number }> {
  let created = 0;
  let updated = 0;
  const now = new Date().toISOString();

  for (const file of changedFiles) {
    const r2Key = `workspace/${userId}/${projectId}/${file.path}`;

    // Decode content
    let contentBytes: Uint8Array;
    if (file.isBinary) {
      const binary = atob(file.content);
      contentBytes = new Uint8Array(binary.length);
      for (let i = 0; i < binary.length; i++) {
        contentBytes[i] = binary.charCodeAt(i);
      }
    } else {
      contentBytes = new TextEncoder().encode(file.content);
    }

    // Upload to R2
    await r2.put(r2Key, contentBytes, {
      httpMetadata: { contentType: file.mimeType },
    });

    // Upsert in D1
    const existing = await db
      .select()
      .from(workspaceFiles)
      .where(
        and(
          eq(workspaceFiles.projectId, projectId),
          eq(workspaceFiles.path, file.path)
        )
      )
      .get();

    if (existing) {
      // Clean up old R2 key if different
      if (existing.r2Key !== r2Key) {
        await r2.delete(existing.r2Key).catch(() => {});
      }
      await db
        .update(workspaceFiles)
        .set({
          mimeType: file.mimeType,
          sizeBytes: contentBytes.byteLength,
          r2Key,
          updatedAt: now,
        })
        .where(eq(workspaceFiles.id, existing.id));
      updated++;
    } else {
      await db.insert(workspaceFiles).values({
        id: crypto.randomUUID(),
        projectId,
        userId,
        path: file.path,
        mimeType: file.mimeType,
        sizeBytes: contentBytes.byteLength,
        r2Key,
        isOutput: file.path.startsWith("output/") ? 1 : 0,
        createdAt: now,
        updatedAt: now,
      });
      created++;
    }
  }

  return { created, updated };
}

function isBinaryMime(mime: string): boolean {
  return (
    mime.startsWith("image/") ||
    mime.startsWith("video/") ||
    mime.startsWith("audio/") ||
    mime === "application/pdf" ||
    mime === "application/zip" ||
    mime.includes("octet-stream")
  );
}
